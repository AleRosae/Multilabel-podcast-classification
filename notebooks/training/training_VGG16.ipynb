{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":14769,"status":"ok","timestamp":1646474692898,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"iUGWjgnpDrWx"},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import models, layers\n","from keras import preprocessing, optimizers\n","from keras_preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17406,"status":"ok","timestamp":1646474710299,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"lNAPhV8uIOWs","outputId":"d78f4a2d-3fad-4b0f-d8a8-d668b85f44c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":49801,"status":"ok","timestamp":1646474760096,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"MKH6sTC_Dnrh"},"outputs":[],"source":["%%capture\n","!unzip /content/drive/MyDrive/Colab_Notebooks/podcast/appledataset/images.zip -d  /content/images"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1109,"status":"ok","timestamp":1646474761200,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"kiGoA76vDsnk"},"outputs":[],"source":["df = pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/podcast/appledataset/podcast_final.csv') # all_podcast_withpaths"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1646474761471,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"NCj7e7QDlXsY"},"outputs":[],"source":["from sklearn.utils import shuffle\n","df = shuffle(df, random_state = 42)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646474761472,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"rfR-ksg_Dtwg","outputId":"560cfa56-bf5a-43c9-830f-dd3df3c6a080"},"outputs":[{"data":{"text/plain":["35"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["len(df['Primary Genre'].value_counts()) #check how many target labels"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646474761472,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"iNqNnM17DviI"},"outputs":[],"source":["filepaths = df['filepaths'].tolist() #change the paths according to colab directory\n","new = []\n","for el in filepaths:\n","  path = el.split('/')[-1]\n","  path= '/content/images/' + path\n","  new.append(path)\n","df['filepaths'] = new"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1646474761787,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"Hu2pbMMYlV-A"},"outputs":[],"source":["df_train = df[:28279]\n","df_test = df[28279:]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1655,"status":"ok","timestamp":1646474763438,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"llks9DjeDx7V","outputId":"10c19d36-f95e-48a7-c04e-b83c88bf5076"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 21210 validated image filenames belonging to 35 classes.\n","Found 7069 validated image filenames belonging to 35 classes.\n","Found 1000 validated image filenames belonging to 35 classes.\n"]}],"source":["datagen=ImageDataGenerator(rescale=1./255,validation_split=0.25)\n","train_generator=datagen.flow_from_dataframe(dataframe=df_train, \n","                                            directory=None, x_col=\"filepaths\", y_col=\"Primary Genre\", \n","                                            class_mode=\"categorical\", target_size=(224,224), batch_size=32,\n","                                            shuffle = True, subset='training')\n","validation_generator=datagen.flow_from_dataframe(dataframe=df_train, \n","                                            directory=None, x_col=\"filepaths\", y_col=\"Primary Genre\", \n","                                            class_mode=\"categorical\", target_size=(224,224), batch_size=32,\n","                                            shuffle = True, subset='validation')\n","\n","test_datagen=ImageDataGenerator(rescale=1./255.)\n","test_generator=test_datagen.flow_from_dataframe(\n","                                            dataframe=df_test,\n","                                            directory=None,\n","                                            x_col=\"filepaths\",\n","                                            y_col='Primary Genre',\n","                                            batch_size=32,\n","                                            target_size=(224,224))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646474763438,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"ZV0YyjT1Dz5l","outputId":"9f472db5-d208-4462-f13f-bdfab47b13d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'After Shows': 0, 'Animation & Manga': 1, 'Arts': 2, 'Books': 3, 'Business': 4, 'Comedy': 5, 'Design': 6, 'Documentary': 7, 'Education': 8, 'Fashion & Beauty': 9, 'Fiction': 10, 'Food': 11, 'Games': 12, 'Health': 13, 'Hobbies': 14, 'Interviews': 15, 'Kids & Family': 16, 'Music': 17, 'Nature': 18, 'News': 19, 'Non-Profit': 20, 'Personal': 21, 'Pets & Animals': 22, 'Places & Travel': 23, 'Politics': 24, 'Religion': 25, 'Science': 26, 'Sexuality': 27, 'Society & Culture': 28, 'Sports': 29, 'Stand-Up': 30, 'TV & Film': 31, 'Technology': 32, 'True Crime': 33, 'Vehicles': 34}\n"]}],"source":["print(validation_generator.class_indices) #returns the classed indices"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6425,"status":"ok","timestamp":1646474769860,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"lhPlj1BEDzzE","outputId":"33fe073b-5442-486c-dff2-4640d73937de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","58900480/58889256 [==============================] - 1s 0us/step\n"]}],"source":["base_model = keras.applications.VGG16(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_shape = (224, 224, 3)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646411819613,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggli2REVr8TL0Puz_pv5w1A4Etul1m3MbAosXhvdQ=s64","userId":"15495324984958389627"},"user_tz":-60},"id":"7lOYXwEuD5nd","outputId":"97fe7fe2-bfd0-4de2-e9d9-ac58ab8f0e08"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 input_1 False\n","1 block1_conv1 False\n","2 block1_conv2 False\n","3 block1_pool False\n","4 block2_conv1 False\n","5 block2_conv2 False\n","6 block2_pool False\n","7 block3_conv1 False\n","8 block3_conv2 False\n","9 block3_conv3 False\n","10 block3_pool False\n","11 block4_conv1 False\n","12 block4_conv2 False\n","13 block4_conv3 False\n","14 block4_pool False\n","15 block5_conv1 False\n","16 block5_conv2 False\n","17 block5_conv3 False\n","18 block5_pool False\n"]}],"source":["# Freeze four convolution blocks\n","for layer in base_model.layers: #[:15]\n","    layer.trainable = False\n","# Make sure you have frozen the correct layers\n","for i, layer in enumerate(base_model.layers):\n","    print(i, layer.name, layer.trainable) #frezee the weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4239,"status":"ok","timestamp":1646411823848,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggli2REVr8TL0Puz_pv5w1A4Etul1m3MbAosXhvdQ=s64","userId":"15495324984958389627"},"user_tz":-60},"id":"GlvxxCZsD6x0","outputId":"3daa6a52-042e-430f-bfc6-623c61c829dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"my_VGG16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 2048)              51382272  \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1024)              2098176   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 35)                35875     \n","                                                                 \n","=================================================================\n","Total params: 68,231,011\n","Trainable params: 53,516,323\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["data_augmentation = keras.Sequential(\n","    [layers.RandomFlip(\"horizontal_and_vertical\"), layers.RandomRotation(0.2)]\n",")\n","\n","# Create new model on top\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = data_augmentation(inputs)  # Apply random data augmentation\n","x = tf.keras.applications.vgg16.preprocess_input(x)\n","# The base model contains batchnorm layers. We want to keep them in inference mode\n","# when we unfreeze the base model for fine-tuning, so we make sure that the\n","# base_model is running in inference mode here.\n","x = base_model.output\n","x = keras.layers.Flatten()(x) # Flatten dimensions to for use in FC layers\n","x = keras.layers.Dense(2048, activation='relu')(x)\n","x = keras.layers.Dropout(0.5)(x) # Dropout layer to reduce overfitting\n","x = keras.layers.Dense(1024, activation = 'relu')(x)\n","x = keras.layers.Dropout(0.5)(x) # Dropout layer to reduce overfitting\n","x = keras.layers.Dense(35, activation = 'softmax')(x)\n","model = keras.Model(inputs=base_model.input, outputs=x, name='my_VGG16')\n","\n","model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4804,"status":"ok","timestamp":1646474774653,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"FOFysH_eyAkU","outputId":"f57765a8-a9c0-4398-fb29-c7114cd8e911"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"my_VGG16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," dense (Dense)               (None, 2048)              51382272  \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1024)              2098176   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 35)                35875     \n","                                                                 \n","=================================================================\n","Total params: 68,231,011\n","Trainable params: 53,516,323\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["model = keras.models.load_model('/content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_1dense2048.h5') #load model to resuming training from checkpoint\n","model.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646474774654,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"YBPg06NXD8gs","outputId":"1e2a833d-c098-477f-c983-fc61d9d7f62b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]}],"source":["model.compile(\n","    optimizer=keras.optimizers.RMSprop(lr=1e-6), #lower lr is better for finetuning\n","    loss=\"categorical_crossentropy\",metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(k=5)]\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15765921,"status":"ok","timestamp":1646490548767,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"oSvT5npED_Bd","outputId":"7d0dfe98-320c-4b5c-8f39-3e1c58b5ba5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 51/100\n","662/662 [==============================] - ETA: 0s - loss: 2.9234 - accuracy: 0.2110 - top_k_categorical_accuracy: 0.5122\n","Epoch 51: val_loss improved from inf to 3.06426, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 341s 494ms/step - loss: 2.9234 - accuracy: 0.2110 - top_k_categorical_accuracy: 0.5122 - val_loss: 3.0643 - val_accuracy: 0.1739 - val_top_k_categorical_accuracy: 0.4510\n","Epoch 52/100\n","662/662 [==============================] - ETA: 0s - loss: 2.9109 - accuracy: 0.2137 - top_k_categorical_accuracy: 0.5147\n","Epoch 52: val_loss improved from 3.06426 to 3.06209, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 300s 453ms/step - loss: 2.9109 - accuracy: 0.2137 - top_k_categorical_accuracy: 0.5147 - val_loss: 3.0621 - val_accuracy: 0.1759 - val_top_k_categorical_accuracy: 0.4516\n","Epoch 53/100\n","662/662 [==============================] - ETA: 0s - loss: 2.9074 - accuracy: 0.2143 - top_k_categorical_accuracy: 0.5197\n","Epoch 53: val_loss improved from 3.06209 to 3.05974, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 292s 441ms/step - loss: 2.9074 - accuracy: 0.2143 - top_k_categorical_accuracy: 0.5197 - val_loss: 3.0597 - val_accuracy: 0.1770 - val_top_k_categorical_accuracy: 0.4527\n","Epoch 54/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8996 - accuracy: 0.2167 - top_k_categorical_accuracy: 0.5203\n","Epoch 54: val_loss improved from 3.05974 to 3.05603, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 293s 443ms/step - loss: 2.8996 - accuracy: 0.2167 - top_k_categorical_accuracy: 0.5203 - val_loss: 3.0560 - val_accuracy: 0.1766 - val_top_k_categorical_accuracy: 0.4541\n","Epoch 55/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8951 - accuracy: 0.2167 - top_k_categorical_accuracy: 0.5229\n","Epoch 55: val_loss did not improve from 3.05603\n","662/662 [==============================] - 288s 435ms/step - loss: 2.8951 - accuracy: 0.2167 - top_k_categorical_accuracy: 0.5229 - val_loss: 3.0569 - val_accuracy: 0.1760 - val_top_k_categorical_accuracy: 0.4537\n","Epoch 56/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8812 - accuracy: 0.2177 - top_k_categorical_accuracy: 0.5251\n","Epoch 56: val_loss improved from 3.05603 to 3.05298, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 293s 442ms/step - loss: 2.8812 - accuracy: 0.2177 - top_k_categorical_accuracy: 0.5251 - val_loss: 3.0530 - val_accuracy: 0.1780 - val_top_k_categorical_accuracy: 0.4533\n","Epoch 57/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8767 - accuracy: 0.2238 - top_k_categorical_accuracy: 0.5297\n","Epoch 57: val_loss improved from 3.05298 to 3.05108, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 292s 442ms/step - loss: 2.8767 - accuracy: 0.2238 - top_k_categorical_accuracy: 0.5297 - val_loss: 3.0511 - val_accuracy: 0.1783 - val_top_k_categorical_accuracy: 0.4537\n","Epoch 58/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8673 - accuracy: 0.2237 - top_k_categorical_accuracy: 0.5333\n","Epoch 58: val_loss improved from 3.05108 to 3.04812, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 293s 442ms/step - loss: 2.8673 - accuracy: 0.2237 - top_k_categorical_accuracy: 0.5333 - val_loss: 3.0481 - val_accuracy: 0.1805 - val_top_k_categorical_accuracy: 0.4564\n","Epoch 59/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8675 - accuracy: 0.2238 - top_k_categorical_accuracy: 0.5312\n","Epoch 59: val_loss did not improve from 3.04812\n","662/662 [==============================] - 302s 455ms/step - loss: 2.8675 - accuracy: 0.2238 - top_k_categorical_accuracy: 0.5312 - val_loss: 3.0494 - val_accuracy: 0.1788 - val_top_k_categorical_accuracy: 0.4551\n","Epoch 60/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8560 - accuracy: 0.2264 - top_k_categorical_accuracy: 0.5324\n","Epoch 60: val_loss improved from 3.04812 to 3.04660, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 293s 443ms/step - loss: 2.8560 - accuracy: 0.2264 - top_k_categorical_accuracy: 0.5324 - val_loss: 3.0466 - val_accuracy: 0.1803 - val_top_k_categorical_accuracy: 0.4558\n","Epoch 61/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8499 - accuracy: 0.2304 - top_k_categorical_accuracy: 0.5369\n","Epoch 61: val_loss improved from 3.04660 to 3.04522, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 294s 444ms/step - loss: 2.8499 - accuracy: 0.2304 - top_k_categorical_accuracy: 0.5369 - val_loss: 3.0452 - val_accuracy: 0.1837 - val_top_k_categorical_accuracy: 0.4575\n","Epoch 62/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8482 - accuracy: 0.2282 - top_k_categorical_accuracy: 0.5379\n","Epoch 62: val_loss improved from 3.04522 to 3.04324, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 295s 445ms/step - loss: 2.8482 - accuracy: 0.2282 - top_k_categorical_accuracy: 0.5379 - val_loss: 3.0432 - val_accuracy: 0.1820 - val_top_k_categorical_accuracy: 0.4585\n","Epoch 63/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8338 - accuracy: 0.2309 - top_k_categorical_accuracy: 0.5426\n","Epoch 63: val_loss improved from 3.04324 to 3.03967, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 292s 440ms/step - loss: 2.8338 - accuracy: 0.2309 - top_k_categorical_accuracy: 0.5426 - val_loss: 3.0397 - val_accuracy: 0.1820 - val_top_k_categorical_accuracy: 0.4597\n","Epoch 64/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8307 - accuracy: 0.2327 - top_k_categorical_accuracy: 0.5466\n","Epoch 64: val_loss improved from 3.03967 to 3.03843, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 292s 442ms/step - loss: 2.8307 - accuracy: 0.2327 - top_k_categorical_accuracy: 0.5466 - val_loss: 3.0384 - val_accuracy: 0.1839 - val_top_k_categorical_accuracy: 0.4577\n","Epoch 65/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8142 - accuracy: 0.2367 - top_k_categorical_accuracy: 0.5480\n","Epoch 65: val_loss improved from 3.03843 to 3.03768, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 297s 448ms/step - loss: 2.8142 - accuracy: 0.2367 - top_k_categorical_accuracy: 0.5480 - val_loss: 3.0377 - val_accuracy: 0.1832 - val_top_k_categorical_accuracy: 0.4604\n","Epoch 66/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8110 - accuracy: 0.2358 - top_k_categorical_accuracy: 0.5512\n","Epoch 66: val_loss improved from 3.03768 to 3.03429, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 291s 439ms/step - loss: 2.8110 - accuracy: 0.2358 - top_k_categorical_accuracy: 0.5512 - val_loss: 3.0343 - val_accuracy: 0.1841 - val_top_k_categorical_accuracy: 0.4621\n","Epoch 67/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8030 - accuracy: 0.2399 - top_k_categorical_accuracy: 0.5537\n","Epoch 67: val_loss improved from 3.03429 to 3.03249, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 293s 442ms/step - loss: 2.8030 - accuracy: 0.2399 - top_k_categorical_accuracy: 0.5537 - val_loss: 3.0325 - val_accuracy: 0.1864 - val_top_k_categorical_accuracy: 0.4609\n","Epoch 68/100\n","662/662 [==============================] - ETA: 0s - loss: 2.8036 - accuracy: 0.2410 - top_k_categorical_accuracy: 0.5558\n","Epoch 68: val_loss improved from 3.03249 to 3.03206, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 293s 443ms/step - loss: 2.8036 - accuracy: 0.2410 - top_k_categorical_accuracy: 0.5558 - val_loss: 3.0321 - val_accuracy: 0.1852 - val_top_k_categorical_accuracy: 0.4655\n","Epoch 69/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7921 - accuracy: 0.2422 - top_k_categorical_accuracy: 0.5589\n","Epoch 69: val_loss improved from 3.03206 to 3.02997, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 297s 448ms/step - loss: 2.7921 - accuracy: 0.2422 - top_k_categorical_accuracy: 0.5589 - val_loss: 3.0300 - val_accuracy: 0.1874 - val_top_k_categorical_accuracy: 0.4641\n","Epoch 70/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7854 - accuracy: 0.2436 - top_k_categorical_accuracy: 0.5592\n","Epoch 70: val_loss improved from 3.02997 to 3.02852, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 295s 446ms/step - loss: 2.7854 - accuracy: 0.2436 - top_k_categorical_accuracy: 0.5592 - val_loss: 3.0285 - val_accuracy: 0.1866 - val_top_k_categorical_accuracy: 0.4625\n","Epoch 71/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7792 - accuracy: 0.2460 - top_k_categorical_accuracy: 0.5662\n","Epoch 71: val_loss did not improve from 3.02852\n","662/662 [==============================] - 303s 457ms/step - loss: 2.7792 - accuracy: 0.2460 - top_k_categorical_accuracy: 0.5662 - val_loss: 3.0292 - val_accuracy: 0.1869 - val_top_k_categorical_accuracy: 0.4639\n","Epoch 72/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7691 - accuracy: 0.2510 - top_k_categorical_accuracy: 0.5681\n","Epoch 72: val_loss improved from 3.02852 to 3.02452, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 293s 442ms/step - loss: 2.7691 - accuracy: 0.2510 - top_k_categorical_accuracy: 0.5681 - val_loss: 3.0245 - val_accuracy: 0.1882 - val_top_k_categorical_accuracy: 0.4648\n","Epoch 73/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7612 - accuracy: 0.2488 - top_k_categorical_accuracy: 0.5717\n","Epoch 73: val_loss did not improve from 3.02452\n","662/662 [==============================] - 289s 436ms/step - loss: 2.7612 - accuracy: 0.2488 - top_k_categorical_accuracy: 0.5717 - val_loss: 3.0246 - val_accuracy: 0.1885 - val_top_k_categorical_accuracy: 0.4655\n","Epoch 74/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7583 - accuracy: 0.2518 - top_k_categorical_accuracy: 0.5717\n","Epoch 74: val_loss did not improve from 3.02452\n","662/662 [==============================] - 297s 448ms/step - loss: 2.7583 - accuracy: 0.2518 - top_k_categorical_accuracy: 0.5717 - val_loss: 3.0247 - val_accuracy: 0.1869 - val_top_k_categorical_accuracy: 0.4658\n","Epoch 75/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7526 - accuracy: 0.2522 - top_k_categorical_accuracy: 0.5708\n","Epoch 75: val_loss improved from 3.02452 to 3.02200, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 307s 464ms/step - loss: 2.7526 - accuracy: 0.2522 - top_k_categorical_accuracy: 0.5708 - val_loss: 3.0220 - val_accuracy: 0.1884 - val_top_k_categorical_accuracy: 0.4649\n","Epoch 76/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7362 - accuracy: 0.2567 - top_k_categorical_accuracy: 0.5789\n","Epoch 76: val_loss improved from 3.02200 to 3.01973, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 318s 480ms/step - loss: 2.7362 - accuracy: 0.2567 - top_k_categorical_accuracy: 0.5789 - val_loss: 3.0197 - val_accuracy: 0.1906 - val_top_k_categorical_accuracy: 0.4659\n","Epoch 77/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7374 - accuracy: 0.2555 - top_k_categorical_accuracy: 0.5785\n","Epoch 77: val_loss improved from 3.01973 to 3.01792, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 309s 466ms/step - loss: 2.7374 - accuracy: 0.2555 - top_k_categorical_accuracy: 0.5785 - val_loss: 3.0179 - val_accuracy: 0.1892 - val_top_k_categorical_accuracy: 0.4663\n","Epoch 78/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7298 - accuracy: 0.2625 - top_k_categorical_accuracy: 0.5792\n","Epoch 78: val_loss improved from 3.01792 to 3.01572, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 318s 480ms/step - loss: 2.7298 - accuracy: 0.2625 - top_k_categorical_accuracy: 0.5792 - val_loss: 3.0157 - val_accuracy: 0.1898 - val_top_k_categorical_accuracy: 0.4673\n","Epoch 79/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7250 - accuracy: 0.2632 - top_k_categorical_accuracy: 0.5782\n","Epoch 79: val_loss did not improve from 3.01572\n","662/662 [==============================] - 305s 460ms/step - loss: 2.7250 - accuracy: 0.2632 - top_k_categorical_accuracy: 0.5782 - val_loss: 3.0158 - val_accuracy: 0.1908 - val_top_k_categorical_accuracy: 0.4678\n","Epoch 80/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7158 - accuracy: 0.2589 - top_k_categorical_accuracy: 0.5835\n","Epoch 80: val_loss improved from 3.01572 to 3.01221, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 318s 480ms/step - loss: 2.7158 - accuracy: 0.2589 - top_k_categorical_accuracy: 0.5835 - val_loss: 3.0122 - val_accuracy: 0.1911 - val_top_k_categorical_accuracy: 0.4686\n","Epoch 81/100\n","662/662 [==============================] - ETA: 0s - loss: 2.7040 - accuracy: 0.2640 - top_k_categorical_accuracy: 0.5910\n","Epoch 81: val_loss improved from 3.01221 to 3.01055, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 311s 470ms/step - loss: 2.7040 - accuracy: 0.2640 - top_k_categorical_accuracy: 0.5910 - val_loss: 3.0106 - val_accuracy: 0.1906 - val_top_k_categorical_accuracy: 0.4706\n","Epoch 82/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6993 - accuracy: 0.2672 - top_k_categorical_accuracy: 0.5886\n","Epoch 82: val_loss improved from 3.01055 to 3.00879, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 317s 478ms/step - loss: 2.6993 - accuracy: 0.2672 - top_k_categorical_accuracy: 0.5886 - val_loss: 3.0088 - val_accuracy: 0.1919 - val_top_k_categorical_accuracy: 0.4685\n","Epoch 83/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6875 - accuracy: 0.2683 - top_k_categorical_accuracy: 0.5943\n","Epoch 83: val_loss did not improve from 3.00879\n","662/662 [==============================] - 305s 461ms/step - loss: 2.6875 - accuracy: 0.2683 - top_k_categorical_accuracy: 0.5943 - val_loss: 3.0101 - val_accuracy: 0.1923 - val_top_k_categorical_accuracy: 0.4707\n","Epoch 84/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6823 - accuracy: 0.2707 - top_k_categorical_accuracy: 0.5938\n","Epoch 84: val_loss did not improve from 3.00879\n","662/662 [==============================] - 313s 472ms/step - loss: 2.6823 - accuracy: 0.2707 - top_k_categorical_accuracy: 0.5938 - val_loss: 3.0094 - val_accuracy: 0.1906 - val_top_k_categorical_accuracy: 0.4662\n","Epoch 85/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6714 - accuracy: 0.2752 - top_k_categorical_accuracy: 0.5983\n","Epoch 85: val_loss improved from 3.00879 to 3.00670, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 309s 466ms/step - loss: 2.6714 - accuracy: 0.2752 - top_k_categorical_accuracy: 0.5983 - val_loss: 3.0067 - val_accuracy: 0.1911 - val_top_k_categorical_accuracy: 0.4706\n","Epoch 86/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6666 - accuracy: 0.2753 - top_k_categorical_accuracy: 0.6033\n","Epoch 86: val_loss improved from 3.00670 to 3.00539, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 309s 466ms/step - loss: 2.6666 - accuracy: 0.2753 - top_k_categorical_accuracy: 0.6033 - val_loss: 3.0054 - val_accuracy: 0.1930 - val_top_k_categorical_accuracy: 0.4720\n","Epoch 87/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6540 - accuracy: 0.2791 - top_k_categorical_accuracy: 0.6053\n","Epoch 87: val_loss improved from 3.00539 to 3.00366, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 318s 481ms/step - loss: 2.6540 - accuracy: 0.2791 - top_k_categorical_accuracy: 0.6053 - val_loss: 3.0037 - val_accuracy: 0.1930 - val_top_k_categorical_accuracy: 0.4727\n","Epoch 88/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6481 - accuracy: 0.2786 - top_k_categorical_accuracy: 0.6090\n","Epoch 88: val_loss did not improve from 3.00366\n","662/662 [==============================] - 304s 460ms/step - loss: 2.6481 - accuracy: 0.2786 - top_k_categorical_accuracy: 0.6090 - val_loss: 3.0038 - val_accuracy: 0.1925 - val_top_k_categorical_accuracy: 0.4723\n","Epoch 89/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6449 - accuracy: 0.2817 - top_k_categorical_accuracy: 0.6078\n","Epoch 89: val_loss improved from 3.00366 to 2.99999, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 308s 465ms/step - loss: 2.6449 - accuracy: 0.2817 - top_k_categorical_accuracy: 0.6078 - val_loss: 3.0000 - val_accuracy: 0.1956 - val_top_k_categorical_accuracy: 0.4710\n","Epoch 90/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6333 - accuracy: 0.2853 - top_k_categorical_accuracy: 0.6116\n","Epoch 90: val_loss did not improve from 2.99999\n","662/662 [==============================] - 305s 460ms/step - loss: 2.6333 - accuracy: 0.2853 - top_k_categorical_accuracy: 0.6116 - val_loss: 3.0025 - val_accuracy: 0.1929 - val_top_k_categorical_accuracy: 0.4729\n","Epoch 91/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6290 - accuracy: 0.2883 - top_k_categorical_accuracy: 0.6098\n","Epoch 91: val_loss did not improve from 2.99999\n","662/662 [==============================] - 302s 457ms/step - loss: 2.6290 - accuracy: 0.2883 - top_k_categorical_accuracy: 0.6098 - val_loss: 3.0002 - val_accuracy: 0.1953 - val_top_k_categorical_accuracy: 0.4756\n","Epoch 92/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6189 - accuracy: 0.2906 - top_k_categorical_accuracy: 0.6176\n","Epoch 92: val_loss improved from 2.99999 to 2.99847, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 310s 467ms/step - loss: 2.6189 - accuracy: 0.2906 - top_k_categorical_accuracy: 0.6176 - val_loss: 2.9985 - val_accuracy: 0.1946 - val_top_k_categorical_accuracy: 0.4737\n","Epoch 93/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6087 - accuracy: 0.2912 - top_k_categorical_accuracy: 0.6211\n","Epoch 93: val_loss improved from 2.99847 to 2.99648, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 310s 468ms/step - loss: 2.6087 - accuracy: 0.2912 - top_k_categorical_accuracy: 0.6211 - val_loss: 2.9965 - val_accuracy: 0.1940 - val_top_k_categorical_accuracy: 0.4733\n","Epoch 94/100\n","662/662 [==============================] - ETA: 0s - loss: 2.6042 - accuracy: 0.2938 - top_k_categorical_accuracy: 0.6199\n","Epoch 94: val_loss improved from 2.99648 to 2.99545, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 311s 469ms/step - loss: 2.6042 - accuracy: 0.2938 - top_k_categorical_accuracy: 0.6199 - val_loss: 2.9954 - val_accuracy: 0.1949 - val_top_k_categorical_accuracy: 0.4714\n","Epoch 95/100\n","662/662 [==============================] - ETA: 0s - loss: 2.5986 - accuracy: 0.2960 - top_k_categorical_accuracy: 0.6223\n","Epoch 95: val_loss improved from 2.99545 to 2.99379, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 321s 484ms/step - loss: 2.5986 - accuracy: 0.2960 - top_k_categorical_accuracy: 0.6223 - val_loss: 2.9938 - val_accuracy: 0.1950 - val_top_k_categorical_accuracy: 0.4760\n","Epoch 96/100\n","662/662 [==============================] - ETA: 0s - loss: 2.5864 - accuracy: 0.2994 - top_k_categorical_accuracy: 0.6264\n","Epoch 96: val_loss improved from 2.99379 to 2.99367, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 322s 486ms/step - loss: 2.5864 - accuracy: 0.2994 - top_k_categorical_accuracy: 0.6264 - val_loss: 2.9937 - val_accuracy: 0.1967 - val_top_k_categorical_accuracy: 0.4760\n","Epoch 97/100\n","662/662 [==============================] - ETA: 0s - loss: 2.5779 - accuracy: 0.3016 - top_k_categorical_accuracy: 0.6314\n","Epoch 97: val_loss did not improve from 2.99367\n","662/662 [==============================] - 316s 477ms/step - loss: 2.5779 - accuracy: 0.3016 - top_k_categorical_accuracy: 0.6314 - val_loss: 2.9942 - val_accuracy: 0.1953 - val_top_k_categorical_accuracy: 0.4766\n","Epoch 98/100\n","662/662 [==============================] - ETA: 0s - loss: 2.5709 - accuracy: 0.3033 - top_k_categorical_accuracy: 0.6288\n","Epoch 98: val_loss improved from 2.99367 to 2.99282, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 310s 468ms/step - loss: 2.5709 - accuracy: 0.3033 - top_k_categorical_accuracy: 0.6288 - val_loss: 2.9928 - val_accuracy: 0.1969 - val_top_k_categorical_accuracy: 0.4754\n","Epoch 99/100\n","662/662 [==============================] - ETA: 0s - loss: 2.5710 - accuracy: 0.3032 - top_k_categorical_accuracy: 0.6278\n","Epoch 99: val_loss improved from 2.99282 to 2.99176, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 310s 468ms/step - loss: 2.5710 - accuracy: 0.3032 - top_k_categorical_accuracy: 0.6278 - val_loss: 2.9918 - val_accuracy: 0.1960 - val_top_k_categorical_accuracy: 0.4753\n","Epoch 100/100\n","662/662 [==============================] - ETA: 0s - loss: 2.5578 - accuracy: 0.3049 - top_k_categorical_accuracy: 0.6345\n","Epoch 100: val_loss improved from 2.99176 to 2.98974, saving model to /content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5\n","662/662 [==============================] - 311s 469ms/step - loss: 2.5578 - accuracy: 0.3049 - top_k_categorical_accuracy: 0.6345 - val_loss: 2.9897 - val_accuracy: 0.1969 - val_top_k_categorical_accuracy: 0.4778\n"]}],"source":["STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n","STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n","\n","CSV_log = tf.keras.callbacks.CSVLogger('/content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_log1dense2018.csv', separator=\",\", append=True)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=7,\n","restore_best_weights=True, monitor='val_loss')\n","model_checkpoint = keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_checkpoint.h5', monitor='val_loss', save_best_only = True, verbose = 1)\n","\n","history = model.fit(x=train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=validation_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    epochs=100, callbacks=[early_stopping_cb, model_checkpoint, CSV_log], initial_epoch = 50)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2414,"status":"ok","timestamp":1646491062445,"user":{"displayName":"Alessandro Rosa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05123586525022219487"},"user_tz":-60},"id":"ZSv3iacAXwpd"},"outputs":[],"source":["model.save('/content/drive/MyDrive/Colab_Notebooks/podcast/VGG16_finetuned_1dense2048.h5')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"training_VGG16.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
