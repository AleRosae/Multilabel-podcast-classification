{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture #libreries for sagemaker\n",
    "!pip install tensorflow==2.8.0\n",
    "!pip install scikit-learn==1.0.2\n",
    "!pip install nltk==3.2.5\n",
    "!python3 -m pip install --upgrade pip\n",
    "!python3 -m pip install --upgrade Pillow\n",
    "!pip install matplotlib\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NGPidcintBe"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip images.zip -d  images_podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2H_OUWvan4Dh",
    "outputId": "7c1eae29-7621-403a-b571-1f4478b7931e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 14:52:14.177971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-12 14:52:14.178005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "from keras import preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from PIL import Image\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense, Input, Bidirectional, Flatten, Conv2D, MaxPooling2D, concatenate, Conv1D, MaxPooling1D,  BatchNormalization, Activation, GRU\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "llJSwO7xoA_0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('podcast_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mMguYMdVoJU-"
   },
   "outputs": [],
   "source": [
    "df = shuffle(df, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-sb4Hv3FojxT"
   },
   "outputs": [],
   "source": [
    "filepaths = df['filepaths'].tolist() #change the paths according to sagemaker directory\n",
    "new = []\n",
    "for el in filepaths:\n",
    "  path = el.split('/')[-1]\n",
    "  path= 'images_podcast/' + path\n",
    "  new.append(path)\n",
    "df['filepaths'] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MoPN5l_LoOcD"
   },
   "outputs": [],
   "source": [
    "#df['Primary Genre'] = [[el]for el in df['Primary Genre'].tolist()]\n",
    "df_train = df[:28279]\n",
    "df_test = df[28279:]\n",
    "df_train, df_valid = train_test_split(df_train, shuffle = True, train_size=0.8, random_state = 65)\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "df_valid.reset_index(inplace = True, drop = True)\n",
    "df_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hheonpckoP2F"
   },
   "outputs": [],
   "source": [
    "stopw = stopwords.words('english')\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_text(text):\n",
    "  text = text.lower().strip()\n",
    "  text = tokenizer.tokenize(text)\n",
    "  clean_text = [w for w in text if w.lower() not in stopw]\n",
    "  clean_text = \" \".join([lemmatizer.lemmatize(w) for w in clean_text])\n",
    "  return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25bOAYbEoRmP",
    "outputId": "9eadcf42-8bbc-4bbe-d219-928f46925a96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/439466514.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['Description'] = [clean_text(el) for el in df_test['Description'].tolist()]\n"
     ]
    }
   ],
   "source": [
    "df_train['Description'] = [clean_text(el) for el in df_train['Description'].tolist()]\n",
    "df_valid['Description'] = [clean_text(el) for el in df_valid['Description'].tolist()]\n",
    "df_test['Description'] = [clean_text(el) for el in df_test['Description'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uIdeDihERrM",
    "outputId": "f1ebe5cb-3cc4-4ad0-859b-1ad4b9873d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96489 unique tokens.\n",
      "Max len: 3979\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = df['Description'].map(len).max()\n",
    "EMBEDDING_DIM = 300\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(df['Description'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print('Max len:', MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 14:52:31.674066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-12 14:52:31.674106: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-12 14:52:31.674130: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2022-03-12 14:52:31.676016: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('full_net_VGG16finetunedbasebatch32.h5') #load model to resume training from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape = (224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 False\n",
      "17 block5_conv3 False\n",
      "18 block5_pool False\n"
     ]
    }
   ],
   "source": [
    "# Freeze four convolution blocks\n",
    "for layer in VGG16.layers: #[:15]\n",
    "    layer.trainable = False\n",
    "# Make sure you have frozen the correct layers\n",
    "for i, layer in enumerate(VGG16.layers):\n",
    "    print(i, layer.name, layer.trainable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XMNgK_YpOKM",
    "outputId": "ed434324-b8b9-46dd-ca49-55776ecbbe2f"
   },
   "outputs": [],
   "source": [
    "#VGG16 + creates RNN\n",
    "data_augmentation = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal_and_vertical\"), layers.RandomRotation(0.2),]\n",
    ")\n",
    "\n",
    "lstm_input = Input(shape=(None,)) #text network\n",
    "x = Embedding(len(word_index), 300, mask_zero=True, input_length=MAX_SEQUENCE_LENGTH, trainable=False)(lstm_input)\n",
    "x = GRU(128, return_sequences = True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = GRU(128, return_sequences = True)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = GRU(128, return_sequences = False)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "lstm_out = Dense(35, activation = 'relu')(x)\n",
    "\n",
    "inputs_VGG16 = Input(shape=(224,224,3)) #images network\n",
    "y = data_augmentation(inputs_VGG16)  # Apply random data augmentation\n",
    "y = tf.keras.applications.vgg16.preprocess_input(y)\n",
    "y = VGG16(y)\n",
    "y = keras.layers.Flatten()(y)\n",
    "y = Dense(512, activation = 'relu')(y)\n",
    "y = Dropout(0.1)(y)\n",
    "vgg16_out =  Dense(35, activation = 'relu')(y)\n",
    "\n",
    "concat_inp = concatenate([vgg16_out, lstm_out]) #concatenate full network\n",
    "z = Dense(1024, activation='relu')(concat_inp)\n",
    "z = Dropout(0.4)(z)\n",
    "output = Dense(35, activation='softmax')(z)\n",
    "\n",
    "model = Model(name= 'my_fullnet', inputs=[inputs_VGG16, lstm_input], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYP_qbL3Ms8Z"
   },
   "source": [
    "Custom generator\n",
    "\n",
    "Keras does not support nativaly mixed data inputs, so I had to build a custom generator that feeds batches of data (images + text + labels) to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hrd1WxAK1Zmb"
   },
   "outputs": [],
   "source": [
    "classes = {'After Shows': 0, 'Animation & Manga': 1, 'Arts': 2, 'Books': 3, 'Business': 4, 'Comedy': 5, 'Design': 6, 'Documentary': 7, 'Education': 8, 'Fashion & Beauty': 9, 'Fiction': 10, 'Food': 11, 'Games': 12, 'Health': 13, 'Hobbies': 14, 'Interviews': 15, 'Kids & Family': 16, 'Music': 17, 'Nature': 18, 'News': 19, 'Non-Profit': 20, 'Personal': 21, 'Pets & Animals': 22, 'Places & Travel': 23, 'Politics': 24, 'Religion': 25, 'Science': 26, 'Sexuality': 27, 'Society & Culture': 28, 'Sports': 29, 'Stand-Up': 30, 'TV & Film': 31, 'Technology': 32, 'True Crime': 33, 'Vehicles': 34}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "C7ykntI9FEFZ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image as krs_image\n",
    "\n",
    "# Create the arguments for image preprocessing\n",
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = df['Description'].map(len).max()\n",
    "EMBEDDING_DIM = 300\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(df['Description'].values)\n",
    "word_index = tokenizer.word_index\n",
    "# Create an empty data generator\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "def custom_generator(subset, batch_size=32):\n",
    "  if subset == 'training':\n",
    "    df = df_train\n",
    "  elif subset == 'testing':\n",
    "    df = df_test\n",
    "  else:\n",
    "    df = df_valid\n",
    "  i = 0\n",
    "  while True:\n",
    "    batch = {'images': [], 'text': [], 'labels': []}\n",
    "    for b in range(batch_size):\n",
    "      if i == len(df):\n",
    "          i = 0\n",
    "      # Read image from list and convert to array\n",
    "      image_path = df.loc[i, \"filepaths\"]\n",
    "      image = krs_image.load_img(image_path, target_size=(224, 224))\n",
    "      image = krs_image.img_to_array(image)\n",
    "\n",
    "      # Read data from csv using the name of current image\n",
    "      label = df.loc[i, \"Primary Genre\"]\n",
    "      text = df.loc[i, 'Description']\n",
    "      text = tokenizer.texts_to_sequences(text)\n",
    "      text = [t[0] for t in text if len(t)!=0]\n",
    "      padding = [0 for _ in range(MAX_SEQUENCE_LENGTH-len(text))]\n",
    "      text = text + padding\n",
    "      #text = pad_sequences(text, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "      \n",
    "      batch['images'].append(image)\n",
    "      batch['text'].append(text)\n",
    "      batch['labels'].append(classes[label])\n",
    "\n",
    "      i += 1\n",
    "    batch['images'] = np.array(batch['images'])\n",
    "    batch['text'] = np.array(batch['text'])\n",
    "    # Convert labels to categorical values\n",
    "    batch['labels'] = np.eye(35)[batch['labels']]\n",
    "\n",
    "    yield [batch['images'], batch['text']], batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xEwTb5_SqZ7x"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(), loss=\"categorical_crossentropy\",metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 2.1129 - accuracy: 0.4192 - top_k_categorical_accuracy: 0.7027\n",
      "Epoch 17: val_loss improved from inf to 2.40394, saving model to full_net_VGG16baseGRU3.h5\n",
      "706/706 [==============================] - 875s 1s/step - loss: 2.1129 - accuracy: 0.4192 - top_k_categorical_accuracy: 0.7027 - val_loss: 2.4039 - val_accuracy: 0.3784 - val_top_k_categorical_accuracy: 0.6294\n",
      "Epoch 18/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 2.0463 - accuracy: 0.4341 - top_k_categorical_accuracy: 0.7133\n",
      "Epoch 18: val_loss improved from 2.40394 to 2.36450, saving model to full_net_VGG16baseGRU3.h5\n",
      "706/706 [==============================] - 858s 1s/step - loss: 2.0463 - accuracy: 0.4341 - top_k_categorical_accuracy: 0.7133 - val_loss: 2.3645 - val_accuracy: 0.3839 - val_top_k_categorical_accuracy: 0.6444\n",
      "Epoch 19/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.9902 - accuracy: 0.4480 - top_k_categorical_accuracy: 0.7297\n",
      "Epoch 19: val_loss did not improve from 2.36450\n",
      "706/706 [==============================] - 860s 1s/step - loss: 1.9902 - accuracy: 0.4480 - top_k_categorical_accuracy: 0.7297 - val_loss: 2.3672 - val_accuracy: 0.3904 - val_top_k_categorical_accuracy: 0.6539\n",
      "Epoch 20/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.9391 - accuracy: 0.4626 - top_k_categorical_accuracy: 0.7432\n",
      "Epoch 20: val_loss did not improve from 2.36450\n",
      "706/706 [==============================] - 864s 1s/step - loss: 1.9391 - accuracy: 0.4626 - top_k_categorical_accuracy: 0.7432 - val_loss: 2.3976 - val_accuracy: 0.3991 - val_top_k_categorical_accuracy: 0.6545\n",
      "Epoch 21/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.8829 - accuracy: 0.4772 - top_k_categorical_accuracy: 0.7538\n",
      "Epoch 21: val_loss did not improve from 2.36450\n",
      "706/706 [==============================] - 859s 1s/step - loss: 1.8829 - accuracy: 0.4772 - top_k_categorical_accuracy: 0.7538 - val_loss: 2.4057 - val_accuracy: 0.4020 - val_top_k_categorical_accuracy: 0.6596\n",
      "Epoch 22/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.8345 - accuracy: 0.4879 - top_k_categorical_accuracy: 0.7628\n",
      "Epoch 22: val_loss did not improve from 2.36450\n",
      "706/706 [==============================] - 837s 1s/step - loss: 1.8345 - accuracy: 0.4879 - top_k_categorical_accuracy: 0.7628 - val_loss: 2.4128 - val_accuracy: 0.4077 - val_top_k_categorical_accuracy: 0.6618\n",
      "Epoch 23/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.7940 - accuracy: 0.4974 - top_k_categorical_accuracy: 0.7734\n",
      "Epoch 23: val_loss did not improve from 2.36450\n",
      "706/706 [==============================] - 861s 1s/step - loss: 1.7940 - accuracy: 0.4974 - top_k_categorical_accuracy: 0.7734 - val_loss: 2.4197 - val_accuracy: 0.4078 - val_top_k_categorical_accuracy: 0.6644\n",
      "Epoch 24/100\n",
      "706/706 [==============================] - ETA: 0s - loss: 1.7463 - accuracy: 0.5069 - top_k_categorical_accuracy: 0.7857\n",
      "Epoch 24: val_loss did not improve from 2.36450\n",
      "706/706 [==============================] - 866s 1s/step - loss: 1.7463 - accuracy: 0.5069 - top_k_categorical_accuracy: 0.7857 - val_loss: 2.4890 - val_accuracy: 0.4075 - val_top_k_categorical_accuracy: 0.6612\n"
     ]
    }
   ],
   "source": [
    "#training VGG16 + custom RNN\n",
    "CSV_log = tf.keras.callbacks.CSVLogger('full_net_VGG16finetunedbasebatch32.csv', separator=\",\", append=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=6,\n",
    "restore_best_weights=True, monitor='val_loss')\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint('full_net_VGG16finetunedbasebatch32.h5', monitor='val_loss', save_best_only = True, verbose = 1)\n",
    "\n",
    "STEP_SIZE_TRAIN=len(df_train)//32\n",
    "STEP_SIZE_VALID=len(df_valid)//32\n",
    "\n",
    "history = model.fit(custom_generator('training'), validation_data=(custom_generator('validation')), \n",
    "                    epochs=100, callbacks=[early_stopping_cb, model_checkpoint, CSV_log], steps_per_epoch=STEP_SIZE_TRAIN, validation_steps = STEP_SIZE_VALID,\n",
    "                    initial_epoch = 16\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_eval = model.evaluate(custom_generator('testing'), steps = len(df_test)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3517343997955322, 'accuracy': 0.4140625, 'top_5_accuracy': 0.6787109375}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "history = {'loss': history_eval[0], 'accuracy': history_eval[1], 'top_5_accuracy': history_eval[2]}\n",
    "print(history)\n",
    "json.dump(history, open('fullnet_eval.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 205s 6s/step\n"
     ]
    }
   ],
   "source": [
    "filenames = df_test['filepaths'].tolist()\n",
    "real_genre = df_test['Primary Genre'].tolist()\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = model.predict(custom_generator('testing'), verbose = 1, steps = nb_samples/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "[1.79916248e-02 1.20362570e-03 1.14894975e-02 6.81950769e-04\n",
      " 1.73103008e-02 3.36533342e-03 8.65048263e-04 7.91200087e-04\n",
      " 6.13070419e-03 3.95816658e-03 4.22820728e-03 3.19670234e-03\n",
      " 3.68652418e-02 2.42632348e-03 7.61923790e-02 1.67034306e-02\n",
      " 1.63473887e-03 4.84089106e-02 1.63522270e-02 1.88836604e-01\n",
      " 3.91481997e-04 3.19714006e-03 8.42044130e-04 6.91072317e-03\n",
      " 5.61812660e-03 5.26376534e-03 7.44604319e-03 9.65712708e-04\n",
      " 2.71364255e-03 1.45787537e-01 2.40173982e-03 2.24964805e-02\n",
      " 2.05191955e-01 4.55174813e-05 1.32095873e-01]\n",
      "[2.62625832e-02 9.09278751e-04 7.44562373e-02 2.79318038e-02\n",
      " 1.18500402e-03 2.47209799e-02 1.51111846e-04 1.38885016e-02\n",
      " 5.84705966e-03 1.06852902e-02 5.24273142e-02 3.21218814e-03\n",
      " 6.30640239e-03 1.45438127e-03 6.87498553e-03 2.29788914e-01\n",
      " 5.60570695e-02 2.11874261e-01 6.07878622e-03 4.33054268e-02\n",
      " 2.21823552e-03 2.30649021e-02 1.16882824e-04 1.71868084e-03\n",
      " 1.20080104e-02 2.56573316e-02 1.07142162e-02 1.37572165e-03\n",
      " 4.96509671e-02 5.03333798e-03 4.18347605e-02 6.66287960e-03\n",
      " 9.84827522e-03 3.33442306e-03 3.34385200e-03]\n"
     ]
    }
   ],
   "source": [
    "print(len(predict))\n",
    "print(predict[-1])\n",
    "print(predict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "[32 15 10 14 17 10 31  4 34 33]\n",
      "[32 15 10 14 17 10 31  4 34 33]\n"
     ]
    }
   ],
   "source": [
    "predicted_class_indices=np.argmax(predict,axis=1)\n",
    "print(len(predicted_class_indices))\n",
    "print(predicted_class_indices[:10])\n",
    "print(predicted_class_indices[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name  \\\n",
      "0  RN Breakfast - Separate stories podcast   \n",
      "\n",
      "                                             Artwork Primary Genre  \\\n",
      "0  https://is5-ssl.mzstatic.com/image/thumb/Podca...          News   \n",
      "\n",
      "                                         Description  \\\n",
      "0  rn breakfast daily story separated easy listen...   \n",
      "\n",
      "                        filepaths  \n",
      "0  images_podcast/id124116392.jpg  \n"
     ]
    }
   ],
   "source": [
    "print(df_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dict((v,k) for k,v in classes.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions[:1000], 'real genre':real_genre, 'description': df[28279:]['Description'].tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>real genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images_podcast/id124116392.jpg</td>\n",
       "      <td>Technology</td>\n",
       "      <td>News</td>\n",
       "      <td>RN Breakfast daily stories separated out for e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images_podcast/id1495557557.jpg</td>\n",
       "      <td>Interviews</td>\n",
       "      <td>Music</td>\n",
       "      <td>For over 4 decades, Bob Clearmountain has defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images_podcast/id1552114238.jpg</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>TV &amp; Film</td>\n",
       "      <td>If you’ve never watched Little House on the Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images_podcast/id1545221046.jpg</td>\n",
       "      <td>Hobbies</td>\n",
       "      <td>Business</td>\n",
       "      <td>No-bullsh*t strategies to help you *CATAPULT* ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images_podcast/id285097604.jpg</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>Presented by Mark Knight: 2 hours of the hotte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images_podcast/id1525926766.jpg</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>The Adventures of Sam Spade, Detective was a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>images_podcast/id1578559817.jpg</td>\n",
       "      <td>TV &amp; Film</td>\n",
       "      <td>TV &amp; Film</td>\n",
       "      <td>It’s one of the wildest scandals in Hollywood ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>images_podcast/id1551541889.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Washington, D.C.‘s fiercest independent report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>images_podcast/id1051566354.jpg</td>\n",
       "      <td>Vehicles</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Justin Robert Young announces his intention to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Filename Predictions real genre  \\\n",
       "0   images_podcast/id124116392.jpg  Technology       News   \n",
       "1  images_podcast/id1495557557.jpg  Interviews      Music   \n",
       "2  images_podcast/id1552114238.jpg     Fiction  TV & Film   \n",
       "3  images_podcast/id1545221046.jpg     Hobbies   Business   \n",
       "4   images_podcast/id285097604.jpg       Music      Music   \n",
       "5  images_podcast/id1525926766.jpg     Fiction    Fiction   \n",
       "6  images_podcast/id1578559817.jpg   TV & Film  TV & Film   \n",
       "7  images_podcast/id1551541889.jpg    Business   Politics   \n",
       "8  images_podcast/id1051566354.jpg    Vehicles   Politics   \n",
       "\n",
       "                                         description  \n",
       "0  RN Breakfast daily stories separated out for e...  \n",
       "1  For over 4 decades, Bob Clearmountain has defi...  \n",
       "2  If you’ve never watched Little House on the Pr...  \n",
       "3  No-bullsh*t strategies to help you *CATAPULT* ...  \n",
       "4  Presented by Mark Knight: 2 hours of the hotte...  \n",
       "5  The Adventures of Sam Spade, Detective was a r...  \n",
       "6  It’s one of the wildest scandals in Hollywood ...  \n",
       "7  Washington, D.C.‘s fiercest independent report...  \n",
       "8  Justin Robert Young announces his intention to...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(9)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_fullnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
